\chapter{Introduction and Background}

What is the strongest biomedical evidence about a disease for discovery of novel pharmaceutical therapies? This is a fundamental challenge for biomedical scientists, but also directly translates to a parallel question for informatics and data science: Can we systematically assemble and query biomedical heterogeneous knowledge graphs in a computational discovery platform guided by rational, algorithmic measures of relevance and confidence, facilitating scientific discovery? And, how have continuing waves of scientific and technological progress informed and empowered these inquiries? 

The research described herein consists of several projects unified by this common theme, each from a distinct area of molecular biomedicine. The three main projects are (1) Badapple: Bioassay data associative promiscuity prediction learning engine, (2) TIGA: Target illumination GWAS analytics, and (3) KGAP: Knowledge graph analytics platform. 

Badapple employs empirical bioassay data from PubChem and the Molecular Libraries Program to recognize patterns of promiscuity (non-selectivity), associated with molecular scaffolds. TIGA processes data from the NHGRI-EBI GWAS Catalog to aggregate experimental genomic variant to trait associations as novel drug target hypotheses.  KGAP combines data from two NIH programs, LINCS (Library of integrated network-based cell signatures)  and IDG (Illuminating the druggable genome) to generate and evaluate hypotheses for novel drug targets. Peer-reviewed papers, with the author as first author, have been published, for Badapple in 2016, TIGA in 2021 and KGAP in 2022. Three additional projects (all with published papers) are also described, for which the author contributed in a non-leading but major role, each different but reinforcing the common theme, that scientific discovery is empowered by rational, algorithmic, semantic, domain-aware assembly and querying of knowledge graphs (or semantically rigorous knowledge-graph-ready datasets). 

This dissertation is closely related to the publications resulting from these projects, and many sections are adaptations of publication sections. By combining these contributions in the context of their common themes and approach, the intended additional benefit is to facilitate application of this approach to additional problem areas. 

\section{Foundations}

This line of investigation builds upon the prior contributions of Wild, Ding, Oprea and others, particularly Chem2Bio2RDF\cite{Chen2010-to}, SLAP\cite{Chen2012-iq}, and IDG\cite{Oprea2018-cp}. These influential resources have contributed to the advancement of systems biology through informatics approaches. Despite progress many challenges remain, for (1) foundational biomedical sciences and understanding complex processes of molecular physiology and pathology, and (2) informatics and data science, to develop effective systems for biomedical knowledge representation, processing, and analysis.  The term "big data" is vague but is a useful shorthand for the problems of data volume, velocity, variety and veracity, which must be addressed in data-intensive areas such as biomedicine.  A centrally important consequence is that access to big data is insufficient, and to be useful, manageable subsets must be searchable and organized for focused analysis.  A simple but profound example of this is Google's initial PageRank algorithm, game-changing for web search, by allowing hundreds of thousands of hits to be manageable by ranking with sufficient relevance for human utility and acceptance.  This research has been motivated by observed use cases where drug discovery scientists focused on a specialized disease area seek to identify and harness the relevant, reliable knowledge to both develop an improved understanding of the underlying biology and explore new hypotheses for drug therapies, whether by novel or repurposed compounds. Key examples are (1) prioritizing hit compounds from a high throughput bioassay, and (2) prioritizing gene hypotheses from GWAS and gene expression datasets.

What types of knowledge are relevant to biomedical and pharmaceutical research?  A wide variety, which may be termed the translational spectrum, from basic science to clinical research and observational data. Given that discoveries build upon knowledge, with stronger knowledge increasing chances for discovery, what are the best measures for confidence?  Confidence evaluation is an essential aspect of any procedure for converting raw data to knowledge.  Assigning confidence levels may also be equivalent to prediction, but in some ways is superior.  Whereas a machine learning (ML) approach may generate a model regardless of the data quality, a confidence level approach should be able to identify cases where the appropriate conclusion is none, an important result in science. Knowledge graphs are well suited to represent human knowledge and provide a platform for research applications. By incorporating measures of confidence and relevance, to evaluate evidence, knowledge graphs can empower and augment human cognition for scientific discovery.

\section{Research area: informatics and data science}

Given the rapid emergence and evolution of informatics and its sub-disciplines, and the newer related designation "data science", a research contribution such as this should be classified in this context to facilitate its interpretation and evaluation. Briefly stated, this work employs methods from bioinformatics and cheminformatics, but its main contributions are best classified as in the realm of data science, and more specifically biomedical data science. Regarding the definition of data science, several have been proposed\cite{ONeil2013-je,Peng2016-gq}, but there is a broad agreement that data science is interdisciplinary and focused on deriving actionable knowledge about the real world. For a data science glossary with related definitions, see Appendix \ref{appendix:glossary_datascience}. In this work, the application area is pharmaceutical discovery, and the real world intent is to advance medical science in the service of improving human health.

\section{Dissertation themes: Metadata, semantics, ontology, knowledge graphs, evidence aggregation and evaluation}

In this dissertation the term \textit{knowledge graph} indicates both the narrow definition of a data structure comprised of nodes and edges, but also in general knowledge representations of entities and relationships defined with semantic rigor, usually via formal ontologies. Generally, the latter is more important to this dissertation, and more important to the effectiveness of data science. Ontology is a branch of philosophy, but in the context of informatics and data science also refers to a concrete, scoped representation of a schema relative to which knowledge can be expressed. Not all the projects described involve knowledge graphs implemented as such, but all reflect emphasis on semantic rigor, with entities and relationships defined by community ontologies and controlled vocabularies, and thus knowledge graph ready and interoperable. Evidence aggregation may appear as a simple count of evidence instances, but accurate counts depend on rigorous definitions, which can be very challenging in practice, for example, counting diabetes patients when diagnostic criteria are varying, controversial, and unevenly implemented. See Appendix table \ref{appendix:glossary_datascience_semantics} for definitions related to data semantics.

\section{Thesis}

The unifying thesis of this dissertation concerns the development and use of measures of confidence and relevance to evaluate biomedical evidence. This is data science methodology. The research projects described involve distinct and separate sub-domains of the biomedical sciences and informatics, but the approaches and methods are related in several respects centered upon the use of confidence and relevance measures to evaluate evidence. In all projects the use cases are from pharmaceutical discovery, specifically lead and target identification and prioritization.  

\section{Novelty}

The novelty of this dissertation consists of (1) the individual novelty of each individual research project, in sum, and (2) the novelty of the common methodological elements, as a general approach to evidence aggregation and evaluation. Novel methods (e.g. Badapple promiscuity score, TIGA RCRAS citation measure) are presented, and existing methods are employed in novel applications.

\section{Validation}

Validation is an important topic for computational and all sciences. A predictive algorithm can prove its value by validation against a dataset of trusted results. Methods presented herein are validated against datasets of trusted results, to the extent possible, but this approach is not fully applicable. Algorithms which are primarily descriptive, rather than predictive, in some sense require no validation except confirmation of their accuracy. For example, the Badapple promiscuity score is strictly speaking an aggregate statistic, combining input bioactivity data, though it may be used in a predictive scenario. Regardless, Badapple was validated using a cross-validation approach. For TIGA and KGAP, designed to associate diseases with druggable genes, an additional challenge is the fundamental uncertainties in molecular biology and medicine, and consequent lack of gold-standard disease-gene associations. For example, the most trusted associations of genes to the disease Type-2 Diabetes are fraught with uncertainty as to their role, and the definitions and diagnoses of the disease itself are at issue. Yet, the medical and public health needs are real and great, thus the need for uncertain methods. 

\section{Researcher contributions}

The research projects described in this dissertation have each been team science efforts producing a peer-reviewed publication. This dissertation combines portions of each project for which the Ph. D. candidate has been the major contributor, and specifies those contributions using the Scholarly Contributions and Roles Ontology (SCoRO)\cite{Shotton2020-ph}. Each of these descriptions has been reviewed and approved by the principal investigator of the corresponding projects. 