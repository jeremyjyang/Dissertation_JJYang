\chapter{Introduction and Background}

What is the strongest biomedical evidence about a disease for discovery of novel pharmaceutical therapies? This is a fundamental challenge for biomedical scientists, but also directly translates to a parallel question for informatics and data science: Can we systematically assemble and query biomedical heterogeneous knowledge graphs in a computational discovery platform guided by rational, algorithmic measures of relevance and confidence, facilitating scientific discovery? And, how have continuing waves of scientific and technological progress informed and empowered these inquiries? 

The research described herein consists of several distinct projects unified by this common theme. The three main projects are (1) Badapple: Bioassay data associative promiscuity prediction learning engine, (2) KGAP: Knowledge graph analytics platform, and (3) TIGA: Target illumination GWAS analytics. 

Badapple employs empirical bioassay data from PubChem and the Molecular Libraries Program to recognize patterns of promiscuity (non-selectivity), associated with molecular scaffolds. 
KGAP combines data from two NIH programs, LINCS (Library of integrated network-based cell signatures)  and IDG (Illuminating the druggable genome) to generate and evaluate hypotheses for novel drug targets. TIGA processes data from the NHGRI-EBI GWAS Catalog to aggregate experimental genomic variant to trait associations as novel drug target hypotheses.  Badapple was published in 2016. Both KGAP and TIGA have led to publications in 2021 (KGAP in 2nd minor revision review, TIGA published 6/4/21). Several other, prior projects are also described, each different but reinforcing the common theme, that scientific discovery is empowered by rational, algorithmic, semantic, domain-aware assembly and querying of knowledge graphs. 

\section{Foundations}

This line of investigation builds upon the prior contributions of Wild, Ding, Oprea and others, particularly Chem2Bio2RDF\cite{Chen2010-to}, SLAP\cite{Chen2012-iq}, and IDG\cite{Oprea2018-cp}. These influential resources have contributed to the advancement of systems biology through informatics approaches.  Despite progress many challenges remain, for (1) foundational biomedical sciences and understanding complex processes of molecular physiology and pathology, and (2) informatics and data science, to develop effective systems for biomedical knowledge representation, processing, and analysis.  The term "big data" is vague but is a useful shorthand for the problems of data volume, velocity, variety and veracity, which must be addressed in data-intensive areas such as biomedicine.  A centrally important consequence is that access to big data is insufficient, and to be useful, manageable subsets must be searchable and organized for focused analysis.  A simple but profound example of this is Google's initial PageRank algorithm, game-changing for web search, by allowing hundreds of thousands of hits to be manageable by ranking with sufficient relevance for human utility and acceptance.  This research has been motivated by observed use cases where drug discovery scientists focused on a specialized disease area seek to identify and harness the relevant, reliable knowledge to both develop an improved understanding of the underlying biology and explore new hypotheses for drug therapies, whether by novel or repurposed compounds. Key examples are (1) prioritizing hit compounds from a high throughput bioassay, and (2) prioritizing gene hypotheses from GWAS and gene expression datasets.

What types of knowledge are relevant to biomedical and pharmaceutical research?  A wide variety, which may be termed the translational spectrum, from basic science to clinical research and observational data. Given that discoveries build upon knowledge, with stronger knowledge increasing chances for discovery, what are the best measures for confidence?  Confidence evaluation is an essential aspect of any procedure for converting raw data to knowledge.  Assigning confidence levels may also be equivalent to prediction, but in some ways is superior.  Whereas an ML approach may generate a model regardless of the data quality, a confidence level approach should be able to identify cases where the appropriate conclusion is none, an important result in science. Knowledge graphs are well suited to represent human knowledge and provide a platform for research applications. By incorporating measures of confidence and relevance, to evaluate evidence, knowledge graphs can empower and augment human cognition for scientific discovery.


\section{Thesis}

The unifying thesis of this dissertation concerns the development and use of measures of confidence and relevance to evaluate biomedical evidence. This is applied methodology. The research projects described involve distinct and separate sub-domains of the biomedical sciences and informatics, but the approaches and methods are related in several respects centered upon the use of confidence and relevance measures to evaluate evidence. In all projects the use cases are from pharmaceutical discovery, specifically lead and target identification and prioritization.  

\section{Novelty}

The novelty of this dissertation consists of (1) the individual novelty of each individual research project, in aggregate, and (2) the novelty of the common methodological elements, as a general approach to evidence evaluation. Novel methods (e.g. Badapple promiscuity formula, TIGA RCRAS citation measure) are presented, and existing methods are employed in novel applications.

\section{Validation}

Validation is an important topic for computational sciences. A predictive algorithm can prove its value by validation against a dataset of trusted results. However, the methods presented herein are generally not amenable to this approach. 

\section{Author contributions}

The research projects described in this dissertation have each been team science efforts producing a peer-reviewed publication. This dissertation combines portions of each project for which the Ph. D. candidate has been the major contributor, and specifies those contributions using the Scholarly Contributions and Roles Ontology (SCoRO)\cite{Shotton2020-ph}. 